{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New attempt\n",
    "Old accuracy: 81,83026200325937"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in ZIP archive: ['train.csv', '__MACOSX/._train.csv']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V38</th>\n",
       "      <th>V39</th>\n",
       "      <th>V40</th>\n",
       "      <th>V41</th>\n",
       "      <th>V42</th>\n",
       "      <th>V43</th>\n",
       "      <th>V44</th>\n",
       "      <th>V45</th>\n",
       "      <th>V46</th>\n",
       "      <th>V47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.37475</td>\n",
       "      <td>0.39650</td>\n",
       "      <td>0.41825</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.42425</td>\n",
       "      <td>0.40850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.42400</td>\n",
       "      <td>0.41400</td>\n",
       "      <td>0.4040</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.3825</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.22167</td>\n",
       "      <td>0.22333</td>\n",
       "      <td>0.22500</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.24000</td>\n",
       "      <td>0.23233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53300</td>\n",
       "      <td>0.42000</td>\n",
       "      <td>0.3070</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.3520</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.33150</td>\n",
       "      <td>0.38500</td>\n",
       "      <td>0.35100</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.67100</td>\n",
       "      <td>0.67667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.60033</td>\n",
       "      <td>0.57367</td>\n",
       "      <td>0.5470</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.4520</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.22800</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.20300</td>\n",
       "      <td>0.20267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53750</td>\n",
       "      <td>0.46000</td>\n",
       "      <td>0.3825</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.2595</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.43700</td>\n",
       "      <td>0.48600</td>\n",
       "      <td>0.53500</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.27000</td>\n",
       "      <td>0.25667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.62900</td>\n",
       "      <td>0.64100</td>\n",
       "      <td>0.6530</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.4365</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1     V2     V3     V4       V5       V6       V7     V8       V9  \\\n",
       "0   9  0.253  0.303  0.353  0.37475  0.39650  0.41825  0.440  0.42425   \n",
       "1   1  0.228  0.210  0.220  0.22167  0.22333  0.22500  0.275  0.24000   \n",
       "2   9  0.281  0.244  0.278  0.33150  0.38500  0.35100  0.564  0.67100   \n",
       "3   1  0.203  0.200  0.197  0.14400  0.18600  0.22800  0.233  0.20300   \n",
       "4  14  0.289  0.369  0.449  0.43700  0.48600  0.53500  0.383  0.27000   \n",
       "\n",
       "       V10  ...      V38      V39     V40    V41    V42    V43     V44    V45  \\\n",
       "0  0.40850  ...  0.42400  0.41400  0.4040  0.394  0.420  0.391  0.3825  0.374   \n",
       "1  0.23233  ...  0.53300  0.42000  0.3070  0.333  0.355  0.355  0.3520  0.349   \n",
       "2  0.67667  ...  0.60033  0.57367  0.5470  0.479  0.505  0.475  0.4520  0.429   \n",
       "3  0.20267  ...  0.53750  0.46000  0.3825  0.305  0.304  0.274  0.2595  0.245   \n",
       "4  0.25667  ...  0.62900  0.64100  0.6530  0.610  0.635  0.511  0.4365  0.362   \n",
       "\n",
       "     V46    V47  \n",
       "0  0.338  0.331  \n",
       "1  0.370  0.391  \n",
       "2  0.432  0.435  \n",
       "3  0.197  0.149  \n",
       "4  0.374  0.348  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import zipfile\n",
    "\n",
    "# Path to the ZIP file\n",
    "zip_file_path = 'train.csv.zip'\n",
    "\n",
    "# Open the ZIP file and list its contents\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as z:\n",
    "    # List all files in the ZIP archive\n",
    "    file_list = z.namelist()\n",
    "    print(\"Files in ZIP archive:\", file_list)\n",
    "    \n",
    "    # Extract the specific CSV file\n",
    "    csv_file_name = 'train.csv'\n",
    "    with z.open(csv_file_name) as f:\n",
    "        train_pd = pd.read_csv(f)\n",
    "\n",
    "train_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "n_iters = 10000\n",
    "num_epochs = 200\n",
    "# Create CNN Model\n",
    "n_timesteps = 46\n",
    "n_outputs = 20\n",
    "\n",
    "n = 199424 # number of samples less than 199424\n",
    "\n",
    "y_np = train_pd.V1.values[:n]\n",
    "x_np = train_pd.loc[:,train_pd.columns != \"V1\"].values[:n, :]\n",
    "y_np = y_np - 1\n",
    "# y goes from 0 to 19\n",
    "\n",
    "x_train_np, x_test_np, y_train_np, y_test_np = train_test_split(x_np, y_np, test_size=0.2) \n",
    "\n",
    "x_train_tensor = torch.from_numpy(x_train_np).type(torch.FloatTensor)\n",
    "y_train_tensor = torch.from_numpy(y_train_np).type(torch.LongTensor)\n",
    "\n",
    "x_test_tensor = torch.from_numpy(x_test_np).type(torch.FloatTensor)\n",
    "y_test_tensor = torch.from_numpy(y_test_np).type(torch.LongTensor)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test = torch.utils.data.TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"Very simple implementation of LSTM-based time-series classifier.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.batch_size = None\n",
    "        self.hidden = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        h0, c0 = self.init_hidden(x)\n",
    "        out, (hn, cn) = self.rnn(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        return h0, c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start model training\n",
      "Epoch 1 best model saved with accuracy: 68.61%\n",
      "Epoch 2 best model saved with accuracy: 72.95%\n",
      "Epoch 3 best model saved with accuracy: 74.49%\n",
      "Epoch 4 best model saved with accuracy: 76.17%\n",
      "Epoch 5 best model saved with accuracy: 77.58%\n",
      "Epoch 6 best model saved with accuracy: 78.31%\n",
      "Epoch 7 best model saved with accuracy: 78.75%\n",
      "Epoch 8 best model saved with accuracy: 78.93%\n",
      "Epoch 9 best model saved with accuracy: 79.30%\n",
      "Epoch 10 best model saved with accuracy: 79.32%\n",
      "Epoch 11 best model saved with accuracy: 79.57%\n",
      "Epoch 12 best model saved with accuracy: 80.02%\n",
      "Epoch 13 best model saved with accuracy: 80.24%\n",
      "Epoch 14 best model saved with accuracy: 80.26%\n",
      "Epoch 16 best model saved with accuracy: 80.60%\n",
      "Epoch 17 best model saved with accuracy: 81.07%\n",
      "Epoch 18 best model saved with accuracy: 81.11%\n",
      "Epoch 19 best model saved with accuracy: 81.27%\n"
     ]
    }
   ],
   "source": [
    "input_dim = 46   \n",
    "hidden_dim = 512\n",
    "layer_dim = 3\n",
    "output_dim = 20\n",
    "seq_dim = 128\n",
    "\n",
    "lr = 0.0005\n",
    "n_epochs = 1000\n",
    "iterations_per_epoch = 500\n",
    "best_acc = 0\n",
    "patience, trials = 100, 0\n",
    "\n",
    "model = LSTMClassifier(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "\n",
    "print('Start model training')\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        model.train()\n",
    "\n",
    "        opt.zero_grad()\n",
    "        out = model(x_batch)\n",
    "        loss = criterion(out, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    for x_val, y_val in test_loader:\n",
    "        out = model(x_val)\n",
    "        preds = F.log_softmax(out, dim=1).argmax(dim=1)\n",
    "        total += y_val.size(0)\n",
    "        correct += (preds == y_val).sum().item()\n",
    "    \n",
    "    acc = correct / total\n",
    "\n",
    "    if epoch % 500 == 0:\n",
    "        print(f'Epoch: {epoch:3d}. Loss: {loss.item():.4f}. Acc.: {acc:2.2%}')\n",
    "\n",
    "    if acc > best_acc:\n",
    "        trials = 0\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(), 'best.pth')\n",
    "        print(f'Epoch {epoch} best model saved with accuracy: {best_acc:2.2%}')\n",
    "    else:\n",
    "        trials += 1\n",
    "        if trials >= patience:\n",
    "            print(f'Early stopping on epoch {epoch}')\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
