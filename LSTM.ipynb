{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New attempt\n",
    "Old accuracy: 81,83026200325937"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in ZIP archive: ['train.csv', '__MACOSX/._train.csv']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V38</th>\n",
       "      <th>V39</th>\n",
       "      <th>V40</th>\n",
       "      <th>V41</th>\n",
       "      <th>V42</th>\n",
       "      <th>V43</th>\n",
       "      <th>V44</th>\n",
       "      <th>V45</th>\n",
       "      <th>V46</th>\n",
       "      <th>V47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.37475</td>\n",
       "      <td>0.39650</td>\n",
       "      <td>0.41825</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.42425</td>\n",
       "      <td>0.40850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.42400</td>\n",
       "      <td>0.41400</td>\n",
       "      <td>0.4040</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.3825</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.22167</td>\n",
       "      <td>0.22333</td>\n",
       "      <td>0.22500</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.24000</td>\n",
       "      <td>0.23233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53300</td>\n",
       "      <td>0.42000</td>\n",
       "      <td>0.3070</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.3520</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.33150</td>\n",
       "      <td>0.38500</td>\n",
       "      <td>0.35100</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.67100</td>\n",
       "      <td>0.67667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.60033</td>\n",
       "      <td>0.57367</td>\n",
       "      <td>0.5470</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.4520</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.22800</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.20300</td>\n",
       "      <td>0.20267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53750</td>\n",
       "      <td>0.46000</td>\n",
       "      <td>0.3825</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.2595</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.43700</td>\n",
       "      <td>0.48600</td>\n",
       "      <td>0.53500</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.27000</td>\n",
       "      <td>0.25667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.62900</td>\n",
       "      <td>0.64100</td>\n",
       "      <td>0.6530</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.4365</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1     V2     V3     V4       V5       V6       V7     V8       V9  \\\n",
       "0   9  0.253  0.303  0.353  0.37475  0.39650  0.41825  0.440  0.42425   \n",
       "1   1  0.228  0.210  0.220  0.22167  0.22333  0.22500  0.275  0.24000   \n",
       "2   9  0.281  0.244  0.278  0.33150  0.38500  0.35100  0.564  0.67100   \n",
       "3   1  0.203  0.200  0.197  0.14400  0.18600  0.22800  0.233  0.20300   \n",
       "4  14  0.289  0.369  0.449  0.43700  0.48600  0.53500  0.383  0.27000   \n",
       "\n",
       "       V10  ...      V38      V39     V40    V41    V42    V43     V44    V45  \\\n",
       "0  0.40850  ...  0.42400  0.41400  0.4040  0.394  0.420  0.391  0.3825  0.374   \n",
       "1  0.23233  ...  0.53300  0.42000  0.3070  0.333  0.355  0.355  0.3520  0.349   \n",
       "2  0.67667  ...  0.60033  0.57367  0.5470  0.479  0.505  0.475  0.4520  0.429   \n",
       "3  0.20267  ...  0.53750  0.46000  0.3825  0.305  0.304  0.274  0.2595  0.245   \n",
       "4  0.25667  ...  0.62900  0.64100  0.6530  0.610  0.635  0.511  0.4365  0.362   \n",
       "\n",
       "     V46    V47  \n",
       "0  0.338  0.331  \n",
       "1  0.370  0.391  \n",
       "2  0.432  0.435  \n",
       "3  0.197  0.149  \n",
       "4  0.374  0.348  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import zipfile\n",
    "\n",
    "# Path to the ZIP file\n",
    "zip_file_path = 'train.csv.zip'\n",
    "\n",
    "# Open the ZIP file and list its contents\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as z:\n",
    "    # List all files in the ZIP archive\n",
    "    file_list = z.namelist()\n",
    "    print(\"Files in ZIP archive:\", file_list)\n",
    "    \n",
    "    # Extract the specific CSV file\n",
    "    csv_file_name = 'train.csv'\n",
    "    with z.open(csv_file_name) as f:\n",
    "        train_pd = pd.read_csv(f)\n",
    "\n",
    "train_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "n_iters = 10000\n",
    "num_epochs = 200\n",
    "# Create CNN Model\n",
    "n_timesteps = 46\n",
    "n_outputs = 20\n",
    "\n",
    "n = 199424 # number of samples less than 199424\n",
    "\n",
    "y_np = train_pd.V1.values[:n]\n",
    "x_np = train_pd.loc[:,train_pd.columns != \"V1\"].values[:n, :]\n",
    "y_np = y_np - 1\n",
    "# y goes from 0 to 19\n",
    "\n",
    "x_train_np, x_test_np, y_train_np, y_test_np = train_test_split(x_np, y_np, test_size=0.2) \n",
    "\n",
    "x_train_tensor = torch.from_numpy(x_train_np).type(torch.FloatTensor)\n",
    "y_train_tensor = torch.from_numpy(y_train_np).type(torch.LongTensor)\n",
    "\n",
    "x_test_tensor = torch.from_numpy(x_test_np).type(torch.FloatTensor)\n",
    "y_test_tensor = torch.from_numpy(y_test_np).type(torch.LongTensor)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test = torch.utils.data.TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"Very simple implementation of LSTM-based time-series classifier.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.batch_size = None\n",
    "        self.hidden = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        h0, c0 = self.init_hidden(x)\n",
    "        out, (hn, cn) = self.rnn(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        return h0, c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 46   \n",
    "hidden_dim = 128\n",
    "layer_dim = 1\n",
    "output_dim = 20\n",
    "seq_dim = 128\n",
    "\n",
    "lr = 0.001\n",
    "n_epochs = 500\n",
    "#iterations_per_epoch = 500\n",
    "best_acc = 0\n",
    "patience, trials = 20, 0\n",
    "\n",
    "model = LSTMClassifier(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.RMSprop(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runnare questo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start model training\n",
      "Epoch 1 best model saved with accuracy: 66.83%\n",
      "Epoch 2 best model saved with accuracy: 69.10%\n",
      "Epoch 3 best model saved with accuracy: 70.62%\n",
      "Epoch 4 best model saved with accuracy: 71.71%\n",
      "Epoch 5 best model saved with accuracy: 72.47%\n",
      "Epoch 6 best model saved with accuracy: 73.09%\n",
      "Epoch 7 best model saved with accuracy: 73.59%\n",
      "Epoch 8 best model saved with accuracy: 73.97%\n",
      "Epoch 9 best model saved with accuracy: 74.36%\n",
      "Epoch 10 best model saved with accuracy: 74.74%\n",
      "Epoch 11 best model saved with accuracy: 75.03%\n",
      "Epoch 12 best model saved with accuracy: 75.26%\n",
      "Epoch 13 best model saved with accuracy: 75.47%\n",
      "Epoch 14 best model saved with accuracy: 75.71%\n",
      "Epoch 15 best model saved with accuracy: 75.87%\n",
      "Epoch 16 best model saved with accuracy: 76.07%\n",
      "Epoch 17 best model saved with accuracy: 76.31%\n",
      "Epoch 18 best model saved with accuracy: 76.48%\n",
      "Epoch 19 best model saved with accuracy: 76.61%\n",
      "Epoch 20 best model saved with accuracy: 76.75%\n",
      "Epoch 21 best model saved with accuracy: 76.89%\n",
      "Epoch 22 best model saved with accuracy: 77.01%\n",
      "Epoch 23 best model saved with accuracy: 77.14%\n",
      "Epoch 24 best model saved with accuracy: 77.19%\n",
      "Epoch 25 best model saved with accuracy: 77.27%\n",
      "Epoch 26 best model saved with accuracy: 77.33%\n",
      "Epoch 27 best model saved with accuracy: 77.42%\n",
      "Epoch 28 best model saved with accuracy: 77.48%\n",
      "Epoch 29 best model saved with accuracy: 77.56%\n",
      "Epoch 30 best model saved with accuracy: 77.60%\n",
      "Epoch 31 best model saved with accuracy: 77.65%\n",
      "Epoch 32 best model saved with accuracy: 77.71%\n",
      "Epoch 33 best model saved with accuracy: 77.79%\n",
      "Epoch 34 best model saved with accuracy: 77.86%\n",
      "Epoch 35 best model saved with accuracy: 77.92%\n",
      "Epoch 36 best model saved with accuracy: 78.00%\n",
      "Epoch 37 best model saved with accuracy: 78.08%\n",
      "Epoch 38 best model saved with accuracy: 78.16%\n",
      "Epoch 39 best model saved with accuracy: 78.21%\n",
      "Epoch 40 best model saved with accuracy: 78.27%\n",
      "Epoch 41 best model saved with accuracy: 78.34%\n",
      "Epoch 42 best model saved with accuracy: 78.40%\n",
      "Epoch 43 best model saved with accuracy: 78.43%\n",
      "Epoch 44 best model saved with accuracy: 78.49%\n",
      "Epoch 45 best model saved with accuracy: 78.55%\n",
      "Epoch 46 best model saved with accuracy: 78.58%\n",
      "Epoch 47 best model saved with accuracy: 78.63%\n",
      "Epoch 48 best model saved with accuracy: 78.67%\n",
      "Epoch 49 best model saved with accuracy: 78.70%\n",
      "Epoch 50 best model saved with accuracy: 78.72%\n",
      "Epoch 51 best model saved with accuracy: 78.77%\n",
      "Epoch 52 best model saved with accuracy: 78.78%\n",
      "Epoch 53 best model saved with accuracy: 78.85%\n",
      "Epoch 54 best model saved with accuracy: 78.88%\n",
      "Epoch 55 best model saved with accuracy: 78.93%\n",
      "Epoch 56 best model saved with accuracy: 78.96%\n",
      "Epoch 57 best model saved with accuracy: 78.99%\n",
      "Epoch 58 best model saved with accuracy: 79.00%\n",
      "Epoch 60 best model saved with accuracy: 79.03%\n",
      "Epoch 61 best model saved with accuracy: 79.09%\n",
      "Epoch 62 best model saved with accuracy: 79.11%\n",
      "Epoch 63 best model saved with accuracy: 79.16%\n",
      "Epoch 64 best model saved with accuracy: 79.18%\n",
      "Epoch 65 best model saved with accuracy: 79.20%\n",
      "Epoch 66 best model saved with accuracy: 79.23%\n",
      "Epoch 67 best model saved with accuracy: 79.28%\n",
      "Epoch 68 best model saved with accuracy: 79.28%\n",
      "Epoch 69 best model saved with accuracy: 79.31%\n",
      "Epoch 70 best model saved with accuracy: 79.34%\n",
      "Epoch 71 best model saved with accuracy: 79.37%\n",
      "Epoch 72 best model saved with accuracy: 79.40%\n",
      "Epoch 75 best model saved with accuracy: 79.42%\n",
      "Epoch 76 best model saved with accuracy: 79.43%\n",
      "Epoch 77 best model saved with accuracy: 79.44%\n",
      "Epoch 78 best model saved with accuracy: 79.47%\n",
      "Epoch 79 best model saved with accuracy: 79.48%\n",
      "Epoch 80 best model saved with accuracy: 79.51%\n",
      "Epoch 81 best model saved with accuracy: 79.51%\n",
      "Epoch 82 best model saved with accuracy: 79.54%\n",
      "Epoch 84 best model saved with accuracy: 79.57%\n",
      "Epoch 85 best model saved with accuracy: 79.59%\n",
      "Epoch 86 best model saved with accuracy: 79.62%\n",
      "Epoch 87 best model saved with accuracy: 79.63%\n",
      "Epoch 88 best model saved with accuracy: 79.65%\n",
      "Epoch 89 best model saved with accuracy: 79.68%\n",
      "Epoch 90 best model saved with accuracy: 79.69%\n",
      "Epoch 91 best model saved with accuracy: 79.71%\n",
      "Epoch 92 best model saved with accuracy: 79.73%\n",
      "Epoch 93 best model saved with accuracy: 79.74%\n",
      "Epoch 95 best model saved with accuracy: 79.75%\n",
      "Epoch 96 best model saved with accuracy: 79.78%\n",
      "Epoch 97 best model saved with accuracy: 79.78%\n",
      "Epoch 98 best model saved with accuracy: 79.81%\n",
      "Epoch 99 best model saved with accuracy: 79.83%\n",
      "Epoch 100 best model saved with accuracy: 79.84%\n",
      "Epoch 101 best model saved with accuracy: 79.85%\n",
      "Epoch 102 best model saved with accuracy: 79.87%\n",
      "Epoch 103 best model saved with accuracy: 79.91%\n",
      "Epoch 104 best model saved with accuracy: 79.92%\n",
      "Epoch 106 best model saved with accuracy: 79.93%\n",
      "Epoch 107 best model saved with accuracy: 79.95%\n",
      "Epoch 108 best model saved with accuracy: 79.98%\n",
      "Epoch 109 best model saved with accuracy: 79.99%\n",
      "Epoch 110 best model saved with accuracy: 80.01%\n",
      "Epoch 111 best model saved with accuracy: 80.02%\n",
      "Epoch 113 best model saved with accuracy: 80.03%\n",
      "Epoch 114 best model saved with accuracy: 80.06%\n",
      "Epoch 115 best model saved with accuracy: 80.10%\n",
      "Epoch 123 best model saved with accuracy: 80.11%\n",
      "Epoch 124 best model saved with accuracy: 80.12%\n",
      "Epoch 125 best model saved with accuracy: 80.15%\n",
      "Epoch 126 best model saved with accuracy: 80.16%\n",
      "Epoch 127 best model saved with accuracy: 80.17%\n",
      "Epoch 128 best model saved with accuracy: 80.18%\n",
      "Epoch 129 best model saved with accuracy: 80.18%\n",
      "Epoch 130 best model saved with accuracy: 80.18%\n",
      "Epoch 131 best model saved with accuracy: 80.20%\n",
      "Epoch 132 best model saved with accuracy: 80.22%\n",
      "Epoch 134 best model saved with accuracy: 80.25%\n",
      "Epoch 135 best model saved with accuracy: 80.26%\n",
      "Epoch 137 best model saved with accuracy: 80.26%\n",
      "Epoch 138 best model saved with accuracy: 80.26%\n",
      "Epoch 139 best model saved with accuracy: 80.27%\n",
      "Epoch 140 best model saved with accuracy: 80.29%\n",
      "Epoch 142 best model saved with accuracy: 80.30%\n",
      "Epoch 143 best model saved with accuracy: 80.32%\n",
      "Epoch 145 best model saved with accuracy: 80.34%\n",
      "Epoch 146 best model saved with accuracy: 80.37%\n",
      "Epoch 147 best model saved with accuracy: 80.40%\n",
      "Epoch 148 best model saved with accuracy: 80.42%\n",
      "Epoch 149 best model saved with accuracy: 80.42%\n",
      "Epoch 151 best model saved with accuracy: 80.43%\n",
      "Epoch 153 best model saved with accuracy: 80.44%\n",
      "Epoch 154 best model saved with accuracy: 80.45%\n",
      "Epoch 155 best model saved with accuracy: 80.46%\n",
      "Epoch 156 best model saved with accuracy: 80.47%\n",
      "Epoch 157 best model saved with accuracy: 80.48%\n",
      "Epoch 158 best model saved with accuracy: 80.48%\n",
      "Epoch 159 best model saved with accuracy: 80.50%\n",
      "Epoch 162 best model saved with accuracy: 80.50%\n",
      "Epoch 163 best model saved with accuracy: 80.52%\n",
      "Epoch 164 best model saved with accuracy: 80.54%\n",
      "Epoch 165 best model saved with accuracy: 80.54%\n",
      "Epoch 166 best model saved with accuracy: 80.55%\n",
      "Epoch 167 best model saved with accuracy: 80.56%\n",
      "Epoch 168 best model saved with accuracy: 80.57%\n",
      "Epoch 169 best model saved with accuracy: 80.57%\n",
      "Epoch 172 best model saved with accuracy: 80.58%\n",
      "Epoch 173 best model saved with accuracy: 80.58%\n",
      "Epoch 176 best model saved with accuracy: 80.60%\n",
      "Epoch 177 best model saved with accuracy: 80.62%\n",
      "Epoch 182 best model saved with accuracy: 80.62%\n",
      "Epoch 183 best model saved with accuracy: 80.64%\n",
      "Epoch 184 best model saved with accuracy: 80.66%\n",
      "Epoch 185 best model saved with accuracy: 80.67%\n",
      "Epoch 186 best model saved with accuracy: 80.70%\n",
      "Epoch 187 best model saved with accuracy: 80.70%\n",
      "Epoch 188 best model saved with accuracy: 80.71%\n",
      "Epoch 190 best model saved with accuracy: 80.72%\n",
      "Epoch 191 best model saved with accuracy: 80.73%\n",
      "Epoch 192 best model saved with accuracy: 80.73%\n",
      "Epoch 193 best model saved with accuracy: 80.74%\n",
      "Epoch 194 best model saved with accuracy: 80.75%\n",
      "Epoch 196 best model saved with accuracy: 80.75%\n",
      "Epoch 197 best model saved with accuracy: 80.76%\n",
      "Epoch 198 best model saved with accuracy: 80.77%\n",
      "Epoch 199 best model saved with accuracy: 80.79%\n",
      "Epoch 200 best model saved with accuracy: 80.81%\n",
      "Epoch 201 best model saved with accuracy: 80.83%\n",
      "Epoch 203 best model saved with accuracy: 80.84%\n",
      "Epoch 204 best model saved with accuracy: 80.84%\n",
      "Epoch 205 best model saved with accuracy: 80.85%\n",
      "Epoch 206 best model saved with accuracy: 80.87%\n",
      "Epoch 207 best model saved with accuracy: 80.89%\n",
      "Epoch 208 best model saved with accuracy: 80.91%\n",
      "Epoch 210 best model saved with accuracy: 80.91%\n",
      "Epoch 211 best model saved with accuracy: 80.92%\n",
      "Epoch 212 best model saved with accuracy: 80.92%\n",
      "Epoch 213 best model saved with accuracy: 80.93%\n",
      "Epoch 214 best model saved with accuracy: 80.94%\n",
      "Epoch 215 best model saved with accuracy: 80.96%\n",
      "Epoch 216 best model saved with accuracy: 80.96%\n",
      "Epoch 217 best model saved with accuracy: 80.97%\n",
      "Epoch 219 best model saved with accuracy: 80.98%\n",
      "Epoch 220 best model saved with accuracy: 80.98%\n",
      "Epoch 221 best model saved with accuracy: 80.99%\n",
      "Epoch 225 best model saved with accuracy: 80.99%\n",
      "Epoch 227 best model saved with accuracy: 81.00%\n",
      "Epoch 229 best model saved with accuracy: 81.01%\n",
      "Epoch 231 best model saved with accuracy: 81.02%\n",
      "Epoch 232 best model saved with accuracy: 81.03%\n",
      "Epoch 233 best model saved with accuracy: 81.03%\n",
      "Epoch 234 best model saved with accuracy: 81.06%\n",
      "Epoch 235 best model saved with accuracy: 81.08%\n",
      "Epoch 236 best model saved with accuracy: 81.09%\n",
      "Epoch 237 best model saved with accuracy: 81.11%\n",
      "Epoch 238 best model saved with accuracy: 81.11%\n",
      "Epoch 239 best model saved with accuracy: 81.12%\n",
      "Epoch 240 best model saved with accuracy: 81.13%\n",
      "Epoch 242 best model saved with accuracy: 81.14%\n",
      "Epoch 243 best model saved with accuracy: 81.15%\n",
      "Epoch 244 best model saved with accuracy: 81.16%\n",
      "Epoch 245 best model saved with accuracy: 81.17%\n",
      "Epoch 246 best model saved with accuracy: 81.18%\n",
      "Epoch 247 best model saved with accuracy: 81.20%\n",
      "Epoch 248 best model saved with accuracy: 81.21%\n",
      "Epoch 249 best model saved with accuracy: 81.22%\n",
      "Epoch 250 best model saved with accuracy: 81.23%\n",
      "Epoch 252 best model saved with accuracy: 81.23%\n",
      "Epoch 253 best model saved with accuracy: 81.24%\n",
      "Epoch 254 best model saved with accuracy: 81.25%\n",
      "Epoch 255 best model saved with accuracy: 81.25%\n",
      "Epoch 256 best model saved with accuracy: 81.26%\n",
      "Epoch 257 best model saved with accuracy: 81.27%\n",
      "Epoch 258 best model saved with accuracy: 81.29%\n",
      "Epoch 261 best model saved with accuracy: 81.29%\n",
      "Epoch 264 best model saved with accuracy: 81.29%\n",
      "Epoch 265 best model saved with accuracy: 81.30%\n",
      "Epoch 266 best model saved with accuracy: 81.30%\n",
      "Epoch 269 best model saved with accuracy: 81.31%\n",
      "Epoch 270 best model saved with accuracy: 81.31%\n",
      "Epoch 271 best model saved with accuracy: 81.32%\n",
      "Epoch 272 best model saved with accuracy: 81.32%\n",
      "Epoch 274 best model saved with accuracy: 81.34%\n",
      "Epoch 276 best model saved with accuracy: 81.35%\n",
      "Epoch 277 best model saved with accuracy: 81.35%\n",
      "Epoch 278 best model saved with accuracy: 81.36%\n",
      "Epoch 280 best model saved with accuracy: 81.36%\n",
      "Epoch 281 best model saved with accuracy: 81.37%\n",
      "Epoch 282 best model saved with accuracy: 81.37%\n",
      "Epoch 283 best model saved with accuracy: 81.38%\n",
      "Epoch 286 best model saved with accuracy: 81.39%\n",
      "Epoch 288 best model saved with accuracy: 81.40%\n",
      "Epoch 289 best model saved with accuracy: 81.42%\n",
      "Epoch 290 best model saved with accuracy: 81.42%\n",
      "Epoch 292 best model saved with accuracy: 81.43%\n",
      "Epoch 296 best model saved with accuracy: 81.43%\n",
      "Epoch 297 best model saved with accuracy: 81.44%\n",
      "Epoch 300 best model saved with accuracy: 81.45%\n",
      "Epoch 301 best model saved with accuracy: 81.46%\n",
      "Epoch 305 best model saved with accuracy: 81.46%\n",
      "Epoch 307 best model saved with accuracy: 81.47%\n",
      "Epoch 308 best model saved with accuracy: 81.48%\n",
      "Epoch 309 best model saved with accuracy: 81.49%\n",
      "Epoch 310 best model saved with accuracy: 81.49%\n",
      "Epoch 311 best model saved with accuracy: 81.50%\n",
      "Epoch 316 best model saved with accuracy: 81.50%\n",
      "Epoch 318 best model saved with accuracy: 81.51%\n",
      "Epoch 323 best model saved with accuracy: 81.51%\n",
      "Epoch 324 best model saved with accuracy: 81.52%\n",
      "Epoch 330 best model saved with accuracy: 81.53%\n",
      "Epoch 331 best model saved with accuracy: 81.54%\n",
      "Epoch 332 best model saved with accuracy: 81.54%\n",
      "Epoch 334 best model saved with accuracy: 81.55%\n",
      "Epoch 341 best model saved with accuracy: 81.55%\n",
      "Epoch 342 best model saved with accuracy: 81.56%\n",
      "Epoch 343 best model saved with accuracy: 81.57%\n",
      "Epoch 353 best model saved with accuracy: 81.57%\n",
      "Epoch 354 best model saved with accuracy: 81.57%\n",
      "Epoch 356 best model saved with accuracy: 81.58%\n",
      "Epoch 359 best model saved with accuracy: 81.58%\n",
      "Epoch 361 best model saved with accuracy: 81.59%\n",
      "Epoch 362 best model saved with accuracy: 81.59%\n",
      "Epoch 365 best model saved with accuracy: 81.60%\n",
      "Epoch 366 best model saved with accuracy: 81.61%\n",
      "Epoch 367 best model saved with accuracy: 81.62%\n",
      "Epoch 369 best model saved with accuracy: 81.62%\n",
      "Epoch 370 best model saved with accuracy: 81.63%\n",
      "Epoch 372 best model saved with accuracy: 81.63%\n",
      "Epoch 373 best model saved with accuracy: 81.63%\n",
      "Epoch 374 best model saved with accuracy: 81.65%\n",
      "Epoch 375 best model saved with accuracy: 81.65%\n",
      "Epoch 377 best model saved with accuracy: 81.66%\n",
      "Epoch 378 best model saved with accuracy: 81.66%\n",
      "Epoch 379 best model saved with accuracy: 81.67%\n",
      "Epoch 380 best model saved with accuracy: 81.68%\n",
      "Epoch 381 best model saved with accuracy: 81.70%\n",
      "Epoch 382 best model saved with accuracy: 81.71%\n",
      "Epoch 383 best model saved with accuracy: 81.71%\n",
      "Epoch 392 best model saved with accuracy: 81.72%\n",
      "Epoch 395 best model saved with accuracy: 81.72%\n",
      "Epoch 396 best model saved with accuracy: 81.73%\n",
      "Epoch 404 best model saved with accuracy: 81.75%\n",
      "Epoch 405 best model saved with accuracy: 81.75%\n",
      "Epoch 413 best model saved with accuracy: 81.76%\n",
      "Epoch 416 best model saved with accuracy: 81.76%\n",
      "Epoch 426 best model saved with accuracy: 81.77%\n",
      "Epoch 427 best model saved with accuracy: 81.78%\n",
      "Epoch 428 best model saved with accuracy: 81.79%\n",
      "Epoch 430 best model saved with accuracy: 81.79%\n",
      "Epoch 434 best model saved with accuracy: 81.79%\n",
      "Epoch 435 best model saved with accuracy: 81.80%\n",
      "Epoch 437 best model saved with accuracy: 81.81%\n",
      "Epoch 440 best model saved with accuracy: 81.81%\n",
      "Epoch 442 best model saved with accuracy: 81.82%\n",
      "Epoch 445 best model saved with accuracy: 81.82%\n",
      "Epoch 446 best model saved with accuracy: 81.83%\n",
      "Epoch 449 best model saved with accuracy: 81.84%\n",
      "Epoch 450 best model saved with accuracy: 81.85%\n",
      "Epoch 451 best model saved with accuracy: 81.85%\n",
      "Epoch 452 best model saved with accuracy: 81.86%\n",
      "Epoch 453 best model saved with accuracy: 81.86%\n",
      "Epoch 454 best model saved with accuracy: 81.86%\n",
      "Epoch 455 best model saved with accuracy: 81.87%\n",
      "Epoch 456 best model saved with accuracy: 81.87%\n",
      "Epoch 457 best model saved with accuracy: 81.88%\n",
      "Epoch 462 best model saved with accuracy: 81.89%\n",
      "Epoch 463 best model saved with accuracy: 81.89%\n",
      "Epoch 464 best model saved with accuracy: 81.89%\n",
      "Epoch 465 best model saved with accuracy: 81.89%\n",
      "Epoch 466 best model saved with accuracy: 81.90%\n",
      "Epoch 468 best model saved with accuracy: 81.90%\n",
      "Epoch 469 best model saved with accuracy: 81.90%\n",
      "Epoch 470 best model saved with accuracy: 81.91%\n",
      "Epoch 472 best model saved with accuracy: 81.91%\n",
      "Epoch 475 best model saved with accuracy: 81.92%\n",
      "Epoch 476 best model saved with accuracy: 81.92%\n",
      "Epoch 484 best model saved with accuracy: 81.92%\n",
      "Epoch 485 best model saved with accuracy: 81.93%\n",
      "Epoch 489 best model saved with accuracy: 81.93%\n",
      "Epoch 491 best model saved with accuracy: 81.94%\n",
      "Epoch 494 best model saved with accuracy: 81.94%\n",
      "Epoch: 500. Loss: 0.5163. Acc.: 81.93%\n"
     ]
    }
   ],
   "source": [
    "print('Start model training')\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        model.train()\n",
    "\n",
    "        opt.zero_grad()\n",
    "        out = model(x_batch)\n",
    "        loss = criterion(out, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    for x_val, y_val in test_loader:\n",
    "        out = model(x_val)\n",
    "        preds = F.log_softmax(out, dim=1).argmax(dim=1)\n",
    "        total += y_val.size(0)\n",
    "        correct += (preds == y_val).sum().item()\n",
    "    \n",
    "    acc = correct / total\n",
    "\n",
    "    if epoch % 500 == 0:\n",
    "        print(f'Epoch: {epoch:3d}. Loss: {loss.item():.4f}. Acc.: {acc:2.2%}')\n",
    "\n",
    "    if acc > best_acc:\n",
    "        trials = 0\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(), 'best.pth')\n",
    "        print(f'Epoch {epoch} best model saved with accuracy: {best_acc:2.2%}')\n",
    "    else:\n",
    "        trials += 1\n",
    "        if trials >= patience:\n",
    "            print(f'Early stopping on epoch {epoch}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 97\u001b[0m\n\u001b[1;32m     94\u001b[0m best_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m param_combinations:\n\u001b[0;32m---> 97\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m score \u001b[38;5;241m>\u001b[39m best_score:\n\u001b[1;32m     99\u001b[0m         best_score \u001b[38;5;241m=\u001b[39m score\n",
      "Cell \u001b[0;32mIn[24], line 64\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     63\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 64\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(out, y_batch)\n\u001b[1;32m     66\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[23], line 16\u001b[0m, in \u001b[0;36mLSTMClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m h0, c0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_hidden(x)\n\u001b[0;32m---> 16\u001b[0m out, (hn, cn) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/rnn.py:917\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    914\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 917\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    920\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    921\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'input_dim': [46],\n",
    "    'hidden_dim': [128, 256, 512],\n",
    "    'layer_dim': [1, 2],\n",
    "    'output_dim': [20],\n",
    "    'seq_dim': [128],\n",
    "    'lr': [0.001, 0.0005],\n",
    "    'batch_size': [64, 128],\n",
    "    'n_epochs': [100, 200],\n",
    "    'patience': [10, 20]\n",
    "}\n",
    "\n",
    "# Create a list of all possible hyperparameter combinations\n",
    "param_combinations = list(product(*param_grid.values()))\n",
    "\n",
    "# Assuming your dataset is already loaded into x_np and y_np\n",
    "x_np = train_pd.loc[:, train_pd.columns != \"V1\"].values\n",
    "y_np = train_pd.V1.values - 1  # Adjust labels if necessary\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "x_tensor = torch.from_numpy(x_np).type(torch.FloatTensor)\n",
    "y_tensor = torch.from_numpy(y_np).type(torch.LongTensor)\n",
    "\n",
    "# Create TensorDataset\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "# Define KFold cross-validator\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Function to train and evaluate the model\n",
    "def train_and_evaluate(params):\n",
    "    input_dim, hidden_dim, layer_dim, output_dim, seq_dim, lr, batch_size, n_epochs, patience = params\n",
    "    best_acc = 0\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "        \n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        model = LSTMClassifier(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
    "        \n",
    "        best_fold_acc = 0\n",
    "        trials = 0\n",
    "        \n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            model.train()\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                out = model(x_batch)\n",
    "                loss = criterion(out, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            model.eval()\n",
    "            correct, total = 0, 0\n",
    "            with torch.no_grad():\n",
    "                for x_val, y_val in val_loader:\n",
    "                    out = model(x_val)\n",
    "                    preds = torch.argmax(out, dim=1)\n",
    "                    total += y_val.size(0)\n",
    "                    correct += (preds == y_val).sum().item()\n",
    "            \n",
    "            acc = correct / total\n",
    "            \n",
    "            if acc > best_fold_acc:\n",
    "                trials = 0\n",
    "                best_fold_acc = acc\n",
    "                if acc > best_acc:\n",
    "                    best_acc = acc\n",
    "            else:\n",
    "                trials += 1\n",
    "                if trials >= patience:\n",
    "                    break\n",
    "    \n",
    "    return best_acc\n",
    "\n",
    "# Perform grid search\n",
    "best_params = None\n",
    "best_score = 0\n",
    "\n",
    "for params in param_combinations:\n",
    "    score = train_and_evaluate(params)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = params\n",
    "\n",
    "print(f'Best Hyperparameters: {best_params}')\n",
    "print(f'Best Accuracy: {best_score:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 128, 1, 20, 128, 0.001, 64, 200, 20)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Accuracy values extracted from the provided text\n",
    "accuracy_values = [\n",
    "    68.61, 72.95, 74.49, 76.17, 77.58, 78.31, 78.75, 78.93, 79.30, 79.32,\n",
    "    79.57, 80.02, 80.24, 80.26, 80.60, 81.07, 81.11, 81.27\n",
    "]\n",
    "\n",
    "# Create a 1D vector\n",
    "accuracy_vector = np.array(accuracy_values)\n",
    "\n",
    "# Plot the accuracy values\n",
    "plt.plot(accuracy_vector, marker='o')\n",
    "plt.title('Model Accuracy Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
